{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Reference Code\n",
    "\n",
    "1) 원래 코드에 주석 달기  \n",
    "2) 새로운 데이터셋 적용하여 돌려보기  \n",
    "3) 구현 시 주의해야할 사항 미리 생각해오기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset  \n",
    "first, download the data from spacy\n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download fr_core_news_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fr_src(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)][::-1]\n",
    "def tokenize_fr_trg(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "def tokenize_fr_src_nltk(text):\n",
    "    return word_tokenize(text, language='french')[::-1]\n",
    "def tokenize_fr_trg_nltk(text):\n",
    "    return word_tokenize(text, language='french')\n",
    "\n",
    "def tokenize_en_src(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)][::-1]\n",
    "def tokenize_en_trg(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "def tokenize_en_src_nltk(text):\n",
    "    return word_tokenize(text, language='english')[::-1]\n",
    "def tokenize_en_trg_nltk(text):\n",
    "    return word_tokenize(text, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FR = Field(tokenize = tokenize_fr_src,\n",
    "               init_token = '<sos>',\n",
    "               eos_token = '<eos>', \n",
    "               lower = True)\n",
    "\n",
    "TRG_EN = Field(tokenize = tokenize_en_trg,\n",
    "               init_token = '<sos>',\n",
    "               eos_token = '<eos>',\n",
    "               lower = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "French (.fr) data are not automatically downloadable.  \n",
    "manually input train.fr and val.fr in ./data/multi30k directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.fr', '.en'), fields = (SRC_FR, TRG_EN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pair_examples(dataset, printing_size=1):\n",
    "    def numeric2ordinal(idx):\n",
    "        if idx == 0:\n",
    "            suff = 'st'\n",
    "        elif idx == 1:\n",
    "            suff = 'nd'\n",
    "        elif idx == 2:\n",
    "            suff = 'rd'\n",
    "        else:\n",
    "            suff = 'th'\n",
    "        return str(idx+1) + suff\n",
    "    data_size = len(dataset.examples)\n",
    "    for _ in range(printing_size):\n",
    "        rand_idx = random.randint(0, data_size)\n",
    "        text_dict = vars(dataset.examples[rand_idx])\n",
    "        print(numeric2ordinal(rand_idx), 'example:')\n",
    "        print('source txt:', ' '.join(text_dict['src'][::-1]))\n",
    "        print('target txt:', ' '.join(text_dict['trg']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7760th example:\n",
      "source txt: de nombreux chiens noirs courent sur une pelouse .\n",
      "target txt: many black dogs run in a grassy area .\n",
      "572th example:\n",
      "source txt: cinq personnes assises autour d' une table , à l' extérieur , jouent à un jeu de cartes .\n",
      "target txt: five people are sitting around a table , outside , playing a card game .\n",
      "1010th example:\n",
      "source txt: un jeune garçon en t - shirt bleu et chapeau vert gonfle un ballon orange .\n",
      "target txt: a young boy in a blue shirt and green hat blows up an orange balloon .\n"
     ]
    }
   ],
   "source": [
    "print_pair_examples(train_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933th example:\n",
      "source txt: un jeune homme fait du skateboard sur un mur de parpaings .\n",
      "target txt: a young man is skateboarding on a cement block wall .\n",
      "966th example:\n",
      "source txt: un homme portant des bottes d' équitation et un casque montant sur un cheval blanc qui saute un obstacle .\n",
      "target txt: a man wearing riding boots and a helmet is riding a white horse , and the horse is jumping a hurdle .\n",
      "962th example:\n",
      "source txt: un cycliste portant un maillot jaune réalise un tour incroyable dans l' air .\n",
      "target txt: a biker wearing a yellow shirt pulls of an incredible trick in the air .\n"
     ]
    }
   ],
   "source": [
    "print_pair_examples(valid_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827th example:\n",
      "source txt: deux jeunes filles sont assises dans la rue , mangeant du maïs .\n",
      "target txt: two young girls are sitting on the street eating corn .\n",
      "597th example:\n",
      "source txt: un groupe de personnes jouent sur un objet .\n",
      "target txt: a group of people are playing on an object .\n",
      "36th example:\n",
      "source txt: un employé donne un sac à une femme tandis qu' elle regarde du poisson sur de la glace sur un marché de rue .\n",
      "target txt: an employee is handing a woman a bag while she is browsing through fish on ice at a street market .\n"
     ]
    }
   ],
   "source": [
    "print_pair_examples(test_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (fr) vocabulary: 6470\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "SRC_FR.build_vocab(train_data, min_freq = 2)\n",
    "TRG_EN.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (fr) vocabulary: {len(SRC_FR.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG_EN.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                                      batch_size = BATCH_SIZE, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        #src = [src len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))  #embedded = [src len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)  #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        #outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):        \n",
    "        #input = [batch size]\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)        \n",
    "        #input = [1, batch size]        \n",
    "        embedded = self.dropout(self.embedding(input))  # embedded = [1, batch size, emb dim]                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))        \n",
    "        #prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        trg_len, batch_size = trg.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)             \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC_FR.vocab)\n",
    "OUTPUT_DIM = len(TRG_EN.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(6470, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,544,453 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model has {param_count:,} trainable parameters')\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG_EN.vocab.stoi[TRG_EN.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):    \n",
    "    model.train()    \n",
    "    epoch_loss = 0    \n",
    "    for i, batch in enumerate(tqdm(iterator)):        \n",
    "        src = batch.src\n",
    "        trg = batch.trg  #trg = [trg len, batch size]\n",
    "        optimizer.zero_grad()        \n",
    "        output = model(src, trg)  #output = [trg len, batch size, output dim]        \n",
    "        output_dim = output.shape[-1]        \n",
    "        output = output[1:].view(-1, output_dim)  #output = [(trg len - 1) * batch size, output dim]\n",
    "        trg = trg[1:].view(-1)  # trg = [(trg len - 1) * batch size]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)        \n",
    "        optimizer.step()        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):    \n",
    "    model.eval()    \n",
    "    epoch_loss = 0    \n",
    "    with torch.no_grad():    \n",
    "        for i, batch in enumerate(tqdm(iterator)):\n",
    "            src = batch.src\n",
    "            trg = batch.trg  #trg = [trg len, batch size]\n",
    "            output = model(src, trg, 0) # output = [trg len, batch size, output dim]\n",
    "            #turn off teacher forcing \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)  # output = [(trg len - 1) * batch size, output dim]\n",
    "            trg = trg[1:].view(-1)  #trg = [(trg len - 1) * batch size]\n",
    "            loss = criterion(output, trg)            \n",
    "            epoch_loss += loss.item()        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e954a431ba4faf83cf3e17d9bfd597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238996d4c43d4c2eb262393c523223af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 01 | Time: 14m 44s\n",
      "\tTrain Loss: 4.849 | Train PPL: 127.602\n",
      "\t Val. Loss: 4.882 |  Val. PPL: 131.903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f712fb4b83b49c0aeabe1136a9fbe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb09db71b0543ba922199e0b2779116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 02 | Time: 14m 53s\n",
      "\tTrain Loss: 4.358 | Train PPL:  78.072\n",
      "\t Val. Loss: 4.698 |  Val. PPL: 109.768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01466c4ac8042f3bbb09759bff8340b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5310beeb636b4c3f9665cef2dd11b872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 03 | Time: 14m 44s\n",
      "\tTrain Loss: 4.081 | Train PPL:  59.182\n",
      "\t Val. Loss: 4.514 |  Val. PPL:  91.314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f87824d52384b21b0cae597425347cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9323c7a98f17458790741d0b5a31cd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 04 | Time: 14m 35s\n",
      "\tTrain Loss: 3.845 | Train PPL:  46.754\n",
      "\t Val. Loss: 4.416 |  Val. PPL:  82.739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0f26156d8444dca2dbfc8e248a451c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f1824c67724c2ea3f9c4113b9e7c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 05 | Time: 14m 41s\n",
      "\tTrain Loss: 3.682 | Train PPL:  39.706\n",
      "\t Val. Loss: 4.159 |  Val. PPL:  64.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15350e8fa49d4d5bb48b2bb0b5e7b0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412bcf7a0eda4d9caf738ba93f088ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 06 | Time: 15m 16s\n",
      "\tTrain Loss: 3.541 | Train PPL:  34.487\n",
      "\t Val. Loss: 4.129 |  Val. PPL:  62.110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec9ec40905d44ea9285cf0a22e36e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113c0d7331834a3c923fd0055f651f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 07 | Time: 13m 52s\n",
      "\tTrain Loss: 3.383 | Train PPL:  29.451\n",
      "\t Val. Loss: 3.975 |  Val. PPL:  53.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09ad0dfc7e04c5790f82244fc3e535a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621fc26a3fe04dd3918f55978b171f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 08 | Time: 13m 8s\n",
      "\tTrain Loss: 3.218 | Train PPL:  24.978\n",
      "\t Val. Loss: 3.828 |  Val. PPL:  45.955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71f03af6c334b4ebc3707c409577fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82c04972ce141a9a1448dec1fffb380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 09 | Time: 12m 57s\n",
      "\tTrain Loss: 3.080 | Train PPL:  21.752\n",
      "\t Val. Loss: 3.808 |  Val. PPL:  45.070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d9b3c30c1e4496a90bea5ef101b34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea833c087b34934ac6cfc593d348f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10 | Time: 13m 6s\n",
      "\tTrain Loss: 2.948 | Train PPL:  19.069\n",
      "\t Val. Loss: 3.772 |  Val. PPL:  43.464\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):    \n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
